{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd                                     \n",
    "import numpy as np                                   \n",
    "import os                                               \n",
    "import matplotlib.pyplot as plt                         \n",
    "import scipy.stats.mstats as ssm                        \n",
    "from scipy.stats import gaussian_kde as kde\n",
    "import random\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Our first task is to transform the dataset into something meaningfully that we can use in our classifier. To do that we are going to aggregate the data based on the player and we are going to do that in the following way:\n",
    "    1. Columns: playerShort, club, leagueCountry, birthday, height, weight and, position just get copied\n",
    "    2. We drop column: player since the playerShort column is unique\n",
    "    3. Columns: games, victories, ties, defeats, goals, yellowCards, yellowReds and, redCards get summed up\n",
    "    4. We drop the photoID column\n",
    "    5. Then we average the rating of the skin colour\n",
    "    6. We then drop columns: refNum, refCountry and, Alpha_3\n",
    "    7. We also drop nIAT, nExp, then average meanIAT, meanExp and calculate new seIAT, seExp based on the variance of the values we used in the averaging of meanIAT and meanExp.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('CrowdstormingDataJuly1st.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check that the data was loaded "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok now, let's make the playerShort the index, also let's average the skintone and drop all players that have the skintone as NaN. Plus, we average the player skintone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df.set_index(df.columns[0], inplace=True)\n",
    "df.dropna(subset=['rater1', 'rater2'], inplace=True)\n",
    "df['skintone']=df[['rater1', 'rater2']].mean(axis=1)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to change the format of the data and keep only relevant fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.drop(['player', 'rater1', 'rater2', 'photoID', 'birthday'], inplace=True, axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now we will collapse these entries so that we have one row per player. We aggregate numerical values either by summing or averaging, and most frequent strings are selected (unless for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "players_grouped = df.groupby(by=['playerShort'])\n",
    "\n",
    "fdict = dict.fromkeys(['club', 'leagueCountry'], lambda x: x.value_counts().index[0])\n",
    "fdict.update({'position': lambda x: x.index[0]})\n",
    "fdict.update(dict.fromkeys(['meanIAT', 'meanExp', 'seIAT', 'seExp', 'height', 'weight', 'skintone'], lambda x: np.mean(x)))\n",
    "fdict.update(dict.fromkeys(['games', 'victories', 'ties', 'defeats', 'goals', 'yellowCards', 'yellowReds', 'redCards'], np.sum))\n",
    "\n",
    "data = players_grouped.agg(fdict)\n",
    "data.reset_index(inplace=True, drop=True)\n",
    "labels = data[['skintone']]\n",
    "data.drop('skintone', inplace=True, axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to deal with the text features. Our model does not like text features so we have to encode them as numbers. There are two ways of doing this.\n",
    "1. We relate each text value to a number\n",
    "2. For each text value we add a new column and set it to 0 where that text value does not appear and 1 where it appers\n",
    "\n",
    "In general it it suggested to use the second aproach, but in our case I will use the first aproach for 2 reasons: \n",
    "-There are a lot of clubs and that will add a lot of columns\n",
    "-It will make it very dificult to inspect the feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le1 = preprocessing.LabelEncoder()\n",
    "le2 = preprocessing.LabelEncoder()\n",
    "le.fit(data['leagueCountry'])\n",
    "le1.fit(data['club'])\n",
    "le2.fit(data['position'].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data['leagueCountry'] = le.transform(data['leagueCountry'])\n",
    "data['club'] = le1.transform(data['club'])\n",
    "data['position'] = data['position'].fillna(le2.inverse_transform(np.median(le2.transform(data['position'].dropna())).astype(int)))\n",
    "data['position'] = le2.transform(data['position'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model also does not like NaN values so we will fill them with the median of the respetive column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['height'] = data['height'].fillna(np.median(data['height'].dropna()))\n",
    "data['weight'] = data['weight'].fillna(np.median(data['weight'].dropna()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#data.set_index(data.columns[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = labels.apply(lambda x: np.round(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn import metrics\n",
    "def checkCrossValidationAccuracy (data, labels):\n",
    "    scores = []\n",
    "    kf = KFold(len(labels), n_folds=20, shuffle=True, random_state=123)\n",
    "    for train_index, test_index in kf:\n",
    "        clf = RandomForestClassifier(n_estimators=15)\n",
    "        X_train, X_test = data.loc[train_index], data.loc[test_index]\n",
    "        y_train, y_test = labels.loc[train_index], labels.loc[test_index]\n",
    "        clf.fit(X_train, y_train['skintone'])\n",
    "        scores.append(metrics.accuracy_score(y_test['skintone'], clf.predict(X_test)))\n",
    "        #print(metrics.accuracy_score(y_test['skintone'], clf.predict(X_test)))\n",
    "        #print(metrics.accuracy_score(y_train['skintone'], clf.predict(X_train)))\n",
    "    return np.average(scores) \n",
    "checkCrossValidationAccuracy(data,labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Okay now let's try dropping some cols. Let's drop the club and the leagueCountry as those atributs should not affect the player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data1 = data.drop(\"leagueCountry\", 1)\n",
    "data1 = data1.drop(\"club\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "checkCrossValidationAccuracy(data1,labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "It looks like droping thoose features did not increase the accuracy but at the same time it simplified the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data2 = data1.drop(\"games\", 1)\n",
    "data2 = data2.drop(\"victories\", 1)\n",
    "data2 = data2.drop(\"ties\", 1)\n",
    "data2 = data2.drop(\"defeats\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "checkCrossValidationAccuracy(data2,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=15)\n",
    "clf.fit(data2, labels['skintone'])\n",
    "clf.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Let's try to join the yellowReds and redCards columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data3 = data2\n",
    "data3['redCards'] = data3['redCards'] + data3['yellowReds']\n",
    "data3 = data3.drop(\"yellowReds\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "checkCrossValidationAccuracy(data3,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=15)\n",
    "clf.fit(data3, labels['skintone'])\n",
    "clf.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Let's also try to remove the position "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data4 = data3.drop(\"position\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "checkCrossValidationAccuracy(data4,labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also try to join the yellow cards and red cards in one column named cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data5 = data4\n",
    "data5['cards'] = data5['redCards'] + data5['yellowCards']\n",
    "data5 = data5.drop('redCards', 1)\n",
    "data5 = data5.drop('yellowCards', 1)\n",
    "data5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "checkCrossValidationAccuracy(data5,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=15)\n",
    "clf.fit(data5, labels['skintone'])\n",
    "clf.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final simplification that we can try is to eleminate all data that is not connected to the cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data6 = data5.drop('height', 1)\n",
    "data6 = data6.drop(\"weight\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "checkCrossValidationAccuracy(data6,labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=15)\n",
    "clf.fit(data6, labels['skintone'])\n",
    "clf.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## PART 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We recuperate the aggregated dataframe we computed earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "part2df = players_grouped.agg(fdict)\n",
    "part2df.reset_index(inplace=True, drop=True)\n",
    "part2df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only want the numeric data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "part2df = part2df._get_numeric_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "part2df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We transform skintone into discrete values 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "part2df['skintone'] = part2df['skintone'].apply(lambda x: 1 if x>=0.5 else 0)\n",
    "part2df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then drop rows that contain at least one NaN, because KMeans can't work with that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "part2df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#part2df.corr()['skintone']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now remove one column at a time and print the result.\n",
    "First we will put skintone in first position since we don't want to drop it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cols = part2df.columns.tolist()\n",
    "for i in range (0, len(cols)):\n",
    "    if(cols[i] == 'skintone'):\n",
    "        cols[0], cols[i] = cols[i], cols[0] #put skintone in first column position, put the old first column where skintone wass\n",
    "shortenedDF = part2df[cols]\n",
    " #scale(shortenedDF)\n",
    "shortenedDF[shortenedDF.columns[1:]]= shortenedDF[shortenedDF.columns[1:]].apply(lambda x: scale(x))\n",
    "shortenedDF.head()\n",
    "#shortenedDF = shortenedDF.drop('position', axis=1) #this column pretty much ruins everything so maybe we should remove it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We now start dropping one column at a time and cluster after each step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kmean = KMeans(n_clusters=2, init='k-means++', n_init=10, max_iter=300, tol=0.0001, precompute_distances='auto', verbose=0, random_state=None, copy_x=True, n_jobs=1)\n",
    "pca_2 = PCA(2)\n",
    "\n",
    "silhouette_scores = []\n",
    "avg_skintones = []\n",
    "for i in range (shortenedDF.shape[1]-1,  1, -1):\n",
    "    shortenedDF = shortenedDF.drop(shortenedDF.columns[i], axis=1)\n",
    "    kmean.fit(shortenedDF)\n",
    "    labels = kmean.labels_\n",
    "    silhouette_scores.append(sklearn.metrics.silhouette_score(shortenedDF, labels, metric='euclidean'))\n",
    "    avg_skintones.append(shortenedDF.groupby(labels).mean()['skintone'].values)\n",
    "    #We'll now use \"principal component analysis\" to plot the output, PCA tries to merge the columns to be able to print them in 2D while keeping the structure of the multidimensional clusters\n",
    "    plot_columns = pca_2.fit_transform(shortenedDF)\n",
    "    plt.scatter(x=plot_columns[:,0], y=plot_columns[:,1], c=labels)\n",
    "    plt.title(shortenedDF.columns.tolist())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "silhouette_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "avg_skintones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
